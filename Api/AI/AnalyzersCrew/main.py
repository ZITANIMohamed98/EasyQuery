from langchain_core.prompts import ChatPromptTemplate
from langchain_ollama.llms import OllamaLLM
import sqlite3
from langchain_core.prompts import ChatPromptTemplate
from langchain_ollama.llms import OllamaLLM
import langchain_community.tools as tools
from langchain_core.tools import tool
from .models import returnReportModel, executeQueryModel
import httpx
import pandas as pd
import os


async def analyze_data(execute_query_model: executeQueryModel) -> str:
    #read the executeQueryModel to get the question and the database name
    question = execute_query_model.input
    database_name = execute_query_model.database_name
    print(f"Analyzing data for question: {question} in database: {database_name}")
    data_queried = await initiate_data(database_name)
    print(f"Data queried: {data_queried.head() if isinstance(data_queried, pd.DataFrame) else data_queried}")
    # analyze data and genrate a report based on the question and the queried data
   
    """
    Analyzes the provided data in the context of the given question using a language model.

    Args:
        question (str): The question to be answered.
        data_queried (Any): The data retrieved from the relevant tables to be analyzed.

    Returns:
        str: The analysis or report generated by the language model based on the question and data.
    """
    # # Extract headers from the queried data
    # if isinstance(data_queried, list) and data_queried:
    #     headers = list(data_queried[0].keys())
    # elif isinstance(data_queried, dict):
    #     headers = list(data_queried.keys())
    # else:
    #     headers = []

    # Template for data analysis and report generation
    template = """
            You are a data analyst. Given the following question and queried data, analyze the data and generate a concise, insightful report.

            Question:
            {question}

            Data:
            {data}

            Instructions:
            - Analyze the data in the context of the question.
            - Identify trends, patterns, or anomalies relevant to the question.
            - Provide a clear, structured report with actionable insights.
            - If the data is insufficient to answer the question, state so explicitly.

            Report:
            """

    prompt = ChatPromptTemplate.from_template(template)

    model = OllamaLLM(model="llama3")

    chain = prompt | model

    response = await chain.ainvoke({
        "question": question,
        "data": data_queried
    })
    if isinstance(response, dict) and 'text' in response:
        return response['text'].strip()  # Stripped of leading/trailing whitespace
    

    elif isinstance(response, str):
         return response.strip()  # Ensure the output is stripped of leading/trailing whitespace
    
    else:
        raise ValueError("Unexpected response type from chain.invoke")
    


async def initiate_data(database_name: str = "salaries.db") -> pd.DataFrame:
    """
    Initiates the data by loading it from a CSV file into a SQLite database and querying a subset of the data.

    Returns:
        pd.DataFrame: A DataFrame containing the queried data.
    """
    db_path = "salaries.db"
    csv_path = "ds_salaries.csv"

    # Only create and populate the database if it doesn't exist
    if not os.path.exists(db_path):
        df = pd.read_csv(csv_path)
        connection = sqlite3.connect(db_path)
        df.to_sql(name="salaries", con=connection, if_exists="replace", index=False)
        connection.close()

    # Now just connect and query
    connection = sqlite3.connect(db_path)
    df = pd.read_sql_query("SELECT * FROM salaries LIMIT 10", connection)
    connection.close()
    return df


# import asyncio

# async def main():
#     result = await analyze_data(execute_query_model=executeQueryModel(
#         user_id="db_user1",
#         activity_id="123",
#         database_name='salaries.db',
#         input='Effects on salary (in USD) based on company location, size and employee experience'
#     ))
#     print(result)

# if __name__ == "__main__":
#     asyncio.run(main())


async def returnReport(execute_query_model: executeQueryModel)->str:
    """
    Makes an HTTP POST request to the /returnReport endpoint using a returnReportModel instance.
    """

    result = await analyze_data(execute_query_model=execute_query_model)
    return result
